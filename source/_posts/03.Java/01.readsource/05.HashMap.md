---
title: 源码解读-HashMap
date: 2018-03-14
tags:
- Java
---
<!-- TOC -->

- [关于Hash](#关于hash)
- [结构](#结构)
- [Hash方法](#hash方法)
- [例](#例)
- [线程安全](#线程安全)
- [fail-fast](#fail-fast)
- [序列化问题](#序列化问题)
- [方法](#方法)
- [WeakHashMap](#weakhashmap)
- [Q&A](#qa)

<!-- /TOC -->

# 关于Hash

通常来说Hash算法具有以下特征,

* 输入和哈希值是多对一的关系,即是一种压缩映射.最优情况是一对一
* 哈希值不同,输入肯定不同
* 哈希值相同,输入可能不同
* 同样的输入,哈希值必须相同
* 不同的输入,同样的哈希值,这种现象被称为哈希碰撞,碰撞几率是衡量一个哈希算法优劣的重要指标.

解决碰撞的方案:

* 开放定址法:一旦发生了冲突，就去寻找下一个空的散列地址，只要散列表足够大，空的散列地址总能找到，并将记录存入
* 链地址法:将哈希表的每个单元作为链表的头结点，所有哈希地址为i的元素构成一个同义词链表。即发生冲突时就把该关键字链在以该单元为头结点的链表的尾部
* 再哈希法:当哈希地址发生冲突用其他的函数计算另一个哈希函数地址，直到冲突不再产生为止
* 建立公共溢出区:将哈希表分为基本表和溢出表两部分，发生冲突的元素都放入溢出表中

HashMap即是采用链地址法,结合数组和链表两者的优势.

# 结构

```Java
// 默认容量
static final int DEFAULT_INITIAL_CAPACITY = 1 << 4;
// 默认扩容因子
static final float DEFAULT_LOAD_FACTOR = 0.75f;
// 链表重构为红黑树的控制因子
static final int TREEIFY_THRESHOLD = 8;
// 扩容临界值
int threshold;
// 节点类
static class Node<K,V> implements Map.Entry<K,V> {
    final int hash;// key的hash值
    final K key;
    V value;
    Node<K,V> next;// key的hash值相同时使用
}
transient Node<K,V>[] table;
transient Set<Map.Entry<K,V>> entrySet;
transient int size;
// 红黑树节点类,向上继承自上面的节点类
static final class TreeNode<K,V> extends LinkedHashMap.Entry<K,V> {
    TreeNode<K,V> parent;  // red-black tree links
    TreeNode<K,V> left;
    TreeNode<K,V> right;
    TreeNode<K,V> prev;    // needed to unlink next upon deletion
    boolean red;
    TreeNode(int hash, K key, V val, Node<K,V> next) {
        super(hash, key, val, next);
    }
}
```

* 默认初始化大小为16,默认使用75%的容量后进行扩容,变为原来的2倍(位运算左移1位)
* 遍历和插入顺序不同
* 存储容器为数组,即代码中的属性table,存储的是节点对象
* key可以为null,重复则会覆盖现有的(默认),也可以使用`putIfAbsent()`方法不覆盖.value也可以为空
* 非线程安全
* 扩容后链表的顺序不再和Java7一样,不会反向
* 存在同一个槽位的key,其hash值可能并不相同,因为还和(capacity-1)进行了与运算

底层:数组+链表(红黑树),初始化是可以自定义初始化大小和扩容因子(有参构造),使用静态内部类对象作为节点,重构后节点类型变为树节点类型,两者存在继承关系.


# Hash方法

```Java
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
// 计算下标
// (n - 1) & hash
```
上面是HashMap的hash算法,及获取下标的计算式,那么就有两个问题:
为什么要自定义一个hash方法?
为什么用hash值与数组长度-1的与操作的结果作为数组的下标?


以默认大小16为例:

|方法|结果|十进制|
|:---|:---|---:|
|h=hashcode()     |0000 0000 0000 0001 1001 1110 0101 1111|106079|
|h >>> 16         |0000 0000 0000 0000 0000 0000 0000 0001|     1|
|hash=h^(h >>> 16)|0000 0000 0000 0001 1001 1110 0101 1110|106078|
|n-1              |0000 0000 0000 0000 0000 0000 0000 1111|    15|
|(n-1)&hash       |0000 0000 0000 0000 0000 0000 0000 1110|    14|

任何数和0异或都是其本身,因此h高16位不变,而数组的大小也是2的幂运算(2的k次方,k>=4),
因此下标由长度的低n位主导,这样会增大hash碰撞的几率,因此在与操作前先进行移位,异或操作使高16位能参与运算以降低碰撞几率.


# 例

```Java
HashMap<String, String> map = new HashMap<>();
map.put("b", "B");
map.put("a", "A");
map.put("c", "C");

// map.entrySet()
// map.keySet()
for (Map.Entry<String, String> entry : map.entrySet()) {
    System.out.println(entry.getKey() + ":" + entry.getValue());
}

Iterator<Map.Entry<String, String>> entryIterator = map.entrySet().iterator();
while (entryIterator.hasNext()) {
    Map.Entry<String, String> a = entryIterator.next();
}

map.forEach((key, value) -> System.out.println(key + ":" + value));
```
以下重点分析大量hash碰撞发生时,链表向红黑树重构的过程:

添加用方法:

put putVal
```Java
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                boolean evict) {
    Node<K,V>[] tab; Node<K,V> p; int n, i;
    if ((tab = table) == null || (n = tab.length) == 0)
        n = (tab = resize()).length;
    if ((p = tab[i = (n - 1) & hash]) == null)// 数组的对应位置没有元素就加进去
        tab[i] = newNode(hash, key, value, null);
    else {// 加进去的地方已经有值,可以简单的认为发生hash碰撞,其实hash值可能并不相同
        Node<K,V> e; K k;
        if (p.hash == hash &&
            ((k = p.key) == key || (key != null && key.equals(k))))// 键允许为空体现在这里,也考虑到使用相同的键添加元素情况
            e = p;
        else if (p instanceof TreeNode)// 红黑树节点,往树上添加节点
            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
        else {// 即不是空键也不是相同的键也没有重构成红黑树时
            for (int binCount = 0; ; ++binCount) {
                if ((e = p.next) == null) {
                    p.next = newNode(hash, key, value, null);// 继续往链表上加
                    if (binCount >= TREEIFY_THRESHOLD - 1) // >=7,即超过8个节点时(=7时,原有8个,上一步加一个,共有9个节点)重构
                        treeifyBin(tab, hash);// 重构操作,在内部将所有节点的类型转为树节点类型(原来的子类)
                    break;
                }
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    break;
                p = e;
            }
        }
        if (e != null) { // existing mapping for key
            V oldValue = e.value;
            if (!onlyIfAbsent || oldValue == null)
                e.value = value;
            afterNodeAccess(e);// LinkedHashMap使用
            return oldValue;
        }
    }
    ++modCount;
    if (++size > threshold)// 扩容校验,超过容量的75%,容量的确定,倍增等都在此方法中实现
        resize();// 具体进行扩容的方法
    afterNodeInsertion(evict);// LinkedHashMap使用
    return null;
}
```

当数组需要扩容时,是调用`resize()`方法,并将旧数组的数组拷贝到新数组中

查找用的方法:

```Java
final Node<K,V> getNode(int hash, Object key) {
    Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
    if ((tab = table) != null && (n = tab.length) > 0 &&
        (first = tab[(n - 1) & hash]) != null) { // 计算出应该存储在数组的哪里,并获取到链上第一个节点
        if (first.hash == hash &&
            ((k = first.key) == key || (key != null && key.equals(k)))) // 判断第一个节点是否是get的对象
            return first;
        if ((e = first.next) != null) {// 不是第一个节点
            if (first instanceof TreeNode)// 此处TreeNode为树对象,满足则走树查找算法
                return ((TreeNode<K,V>)first).getTreeNode(hash, key);
            do { // 链表没有没有重构为红黑树,遍历整个链表
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    return e;
            } while ((e = e.next) != null);
        }
    }
    return null;
}
```

删除时也是类似,先判断数组中的是否是要查找的,不是则判断是链式结构还是树形结构进行查找,删除.

# 线程安全

上面说到HashMap是非线程安全的,那么在并发环境下使用HashMap会有什么后果呢?

在Java7中,扩容完成后会执行下面的代码,其作用是将旧table的数据移到扩容后的新table中去:
[源码地址](https://github.com/lambdalab-mirror/jdk7u-jdk/blob/master/src/share/classes/java/util/HashMap.java#L589)
```Java
void transfer(Entry[] newTable, boolean rehash) {
    int newCapacity = newTable.length;
    for (Entry<K,V> e : table) {
        while(null != e) {
            Entry<K,V> next = e.next;
            if (rehash) {
                e.hash = null == e.key ? 0 : hash(e.key);
            }
            int i = indexFor(e.hash, newCapacity);
            e.next = newTable[i];
            newTable[i] = e;
            e = next;
        }
    }
}
```

可以看出来,如果其中的连续节点经过rehash后仍然在同一个链表(即第9行的i相同),那么迁移后这2个节点顺序就会反向.
假设有这样一个并发环境,线程1执行到第5行后,线程2将上述整个过程执行完,那么2之后的数据就是`node1.next -> node2`,但此时线程1中,e为node2,next(即node2.next)为node1,
对于线程1整体看来就是`node2.next -> node1,node1.next -> node2`,于是形成环状结构,出现死循环,即使这个死循环能够跳出来,那么查找这个链表上的数据时也会出现死循环.

这种情况下就需要使用jdk的命令确定错误的发生场所:`jps,jstack`,值得注意的是,虽然是非线程安全的,但并不是在并发下使用就一定会出现这种情况.

Java8中不再使用上面的结构,扩容和数据迁移都是在`resize()`方法中实现,
[源码地址](https://github.com/lambdalab-mirror/jdk8u-jdk/blob/master/src/share/classes/java/util/HashMap.java#L714)
```Java
Node<K,V> loHead = null, loTail = null;// 原下标位置的链表
Node<K,V> hiHead = null, hiTail = null;// 新位置的链表
Node<K,V> next;
do {
    next = e.next;
    if ((e.hash & oldCap) == 0) { // 判断扩容前后槽位是否变化
        if (loTail == null)
            loHead = e;
        else
            loTail.next = e;
        loTail = e;
    }
    else { // 槽位发生变化的key
        if (hiTail == null)
            hiHead = e;
        else
            hiTail.next = e;
        hiTail = e;
    }
} while ((e = next) != null);
if (loTail != null) {
    loTail.next = null;
    newTab[j] = loHead;
}
if (hiTail != null) {
    hiTail.next = null;
    newTab[j + oldCap] = hiHead;
}
```

上面这一段代码发生在扩容完成后,数据迁移时某个槽位内容为链表(内容为单元素,红黑树以外)时,可以看到是将一个链表分成了2个链表,新位置的确定也不再使用rehash,不会再出现环状结构.

另外,我们知道在同一个槽位的hash值不一定相同,那么什么样的key被放入哪个链表中呢?
下面以容量16扩容到32为例:
扩容前:
| 最大下标/key | 二进制                                  |
| :----------- | :-------------------------------------- |
| n-1(15)      | 0000 0000 0000 0000 0000 0000 0000 1111 |
| key1         | 1111 1111 1111 1111 0000 1111 0000 0101 |
| key1^(n-1)   | 0000 0000 0000 0000 0000 0000 0000 0101 |
| key2         | 1111 1111 1111 1111 0000 1111 0001 0101 |
| key2^(n-1)   | 0000 0000 0000 0000 0000 0000 0000 0101 |

扩容后:
| 最大下标/key | 二进制                                  |
| :----------- | :-------------------------------------- |
| n-1(31)      | 0000 0000 0000 0000 0000 0000 0001 1111 |
| key1         | 1111 1111 1111 1111 0000 1111 0000 0101 |
| key1^(n-1)   | 0000 0000 0000 0000 0000 0000 0000 0101 |
| key2         | 1111 1111 1111 1111 0000 1111 0001 0101 |
| key2^(n-1)   | 0000 0000 0000 0000 0000 0000 0001 0101 |

通过或运算计算槽位,但在扩容前key1和key2在同一个槽位,但扩容后就不在一个槽位了.
上面代码中有个条件`(e.hash & oldCap) == 0`,满足这个条件的处在原槽位不动,不满足的则移动到`原槽位+oldCap`的槽位.

但为什么满足这个条件的就是扩容前后槽位计算结果不会发生变化的呢?
因为容量是2的指数幂结果,二进制表现就是只有`指数+1`位为1,其他为0,
既然结果为0,那么hashcode的该位肯定为0,扩容前后,该位的与运算的结果都是0,即使扩容将`容量-1`的该位从0变为了1.

对于那些槽位会发生变化的key来说,其变化正好是增加了半个新容量(整个旧容量)的大小.

虽然Java8已经不会引起死循环但数据丢失的问题仍然存在,因此还是不推荐在并发环境下使用HashMap.

或使用`Collections.synchronizedMap()`构建线程安全的.

# fail-fast

HashMap的迭代器(Iterator)是`fail-fast`迭代器, 而Hashtable的enumerator迭代器不是`fail-fast`的.

所以当有其它线程改变了HashMap的结构（增减元素时）, 将会抛出`ConcurrentModificationException`,

但迭代器本身的remove()方法移除元素则不会抛出`ConcurrentModificationException`异常.

值得注意的是这并不是一定发生的行为,它只是一种错误检测机制,不可能对是否出现并发修改作出任何保证.这条同样也是`Enumeration`和`Iterator`的区别

# 序列化问题

阅读源码知道,HashMaphe和ArrayList一样都实现了Serializable接口,
但最终的存储容器table确实被transient修饰的,也就是说这个属性在序列化的时候被忽略,
原因我们知道是因为当一个key是自定义对象时,如果没有正确重写hashCode()方法的话,在不同环境下的hash值可能不同,这也就是推荐使用String等对象做key的原因.
另外就是table中有很多null的,这些null是没有必要序列化的,

序列化一个类的对象时,如果这个类实现了writeObject和readObject方法,就会使用这两个方法进行序列化和反序列化,

没实现就使用defaultWriteObject()和defaultReadObject()方法

而HashMap实现了这两个方法:
```Java
private void writeObject(java.io.ObjectOutputStream s)
private void readObject(java.io.ObjectInputStream s)
```

# 方法

**putIfAbsent()**

向map中添加k-v时先判断其是否存在, 不存在则会进行添加并返回null, 如果存在则不会继续操作直接返回已经存在的值.

在HashMap和ConcurrentHashMap中虽然对此方法有重写, 但仍保持着不覆盖现有的做法.

**computeIfAbsent()**

`public V computeIfAbsent(K key, Function<? super K, ? extends V> mappingFunction)`

当map对象调用此方法时, 会先判断是否有指定key的k-v, 没有则会使用mappingFunction计算key对应的value, 然后将k-v存入map,

有则会直接读取. 常用于实现Java本地缓存, 使用例如下:

```Java
static int fibonacci(int i) {
    if (i == 0 || i == 1)
        return i;

    return cache.computeIfAbsent(i, (key) -> {
        return fibonacci(i - 2) + fibonacci(i - 1);
    });
}
```

> 类似的方法还有`computeIfPresent()`和`compute()`, 但作用有所不同

# WeakHashMap

内存缓存


# Q&A

***键***

要计算hashCode(),就要防止键改变,存取时键的值不同,其hashcode会不同,这样是不能正确取出值的.

使用不可变的、声明作final的对象,并且采用合适的equals()和hashCode()方法的话,将会减少碰撞的发生,提高效率.

不可变性使得能够缓存不同键的hashcode,这将提高整个获取对象的速度,因此推荐使用String,Interger这样的wrapper类

因为包装类的一个对象一经创建,其所代表的值将不再变化,也就是说不能通过改变其引用来改变它的值,直至它被垃圾回收器回收

***HashMap和HashTable的区别***

**HashMap自己写了一个hash方法来计算hash值, 为什么不用key本身的hashCode方法, 而是又处理了一下?**



[![](https://static.segmentfault.com/v-5b1df2a7/global/img/creativecommons-cc.svg)](https://creativecommons.org/licenses/by-nc-nd/4.0/)