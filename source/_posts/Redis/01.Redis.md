---
title: Redis
date: 2017-05-11
tags:
- Redis
- NoSQL
---

<!-- TOC -->

- [关于](#关于)
- [配置](#配置)
- [使用](#使用)
- [命令](#命令)
    - [共有命令](#共有命令)
- [数据类型](#数据类型)
    - [String](#string)
    - [list](#list)
    - [hash](#hash)
    - [set](#set)
    - [zset](#zset)
- [调用Redis](#调用redis)
- [持久化](#持久化)
- [主从复制](#主从复制)

<!-- /TOC -->

# 关于

使用场景:

* 分布式缓存
* 分布式session
* 数据量大,高并发的场景下

特点:

* key-value形式存储
* 单进程单线程,区别于Memcached的单进程多线程

Redis 将数据储存在内存里面,读写数据的时候都不会受到硬盘 I/O 速度的限制,所以速度极快

Redis和Memcache
* 都是内存数据库,但Memcache还可以缓存其他东西,如图片视频
* Redis支持数据持久化,memcache挂掉后，数据不可恢复
* Redis有数据类型所以会占用更多的空间
* Redis原生支持集群
* 支持分布式,memcache集群，利用magent做一主多从;redis可以做一主多从,也可以一主一从

Memcache相关可以阅读[Memcache详细解读](http://www.cnblogs.com/xrq730/p/4948707.html)

# 配置

config命令
```
#获取配置信息
config get settingname
config set settingname value
```

设置密码
```
config set requirepass 1121
redis-cli -h 127.0.0.1 -p 6379 -a 1121
```

配置后台运行
redis.conf
```
# daemonize no
daemonize yes
```

# 使用

启动服务

```
redis-server redis.conf
```

关闭服务
```
redis-cli shutdown
```

进入命令行
```
redis-cli -h host -p port -a password
```

> 默认监听`6379`端口

# 命令

格式
```shell

```

## 共有命令

```shell
# 取出所有key
keys *
# 支持正则表达式
keys "foo*"
# 查看数据类型
type <key>
# 重命名key
rename <key>
# 追加value
append <key>
# 判断存在
exists <key>
set: 插入键值, 存在则覆盖
setnx: 插入键值, 存在不覆盖
mset: 批量插入键值, 覆盖
msetnx: 批量插入键值, 不覆盖
getset <key>: 取值并设置新值

incr <key>: 增1
decr <key>: 减1
incrby <key> <i>: 增i
decrby <key> <i>: 减i
```

```shell
# 键值对数量
dbsize
# 清空数据库
flushdb
# 服务信息
info
```

# 数据类型

> 不能存储中文, 存储unicode可以实现间接存储中文

## String

常用命令

```Shell
set
get
# 和set的不同在于返回旧值
getset
# 批量设值
mset k1 v1 k2 v2
mget k1 k2
# key存在则什么都不做,不存在与set相同
setnx k v
# mset和setnx的组合效果,如果任意key存在,则全部都不设值
msetnx k1 v1 k2 v2
# 在set基础上设置过期时间,使用ttl查看剩余时间
setex key seconds value
# 同setex,时间单位是毫秒,使用pttl查看剩余时间
psetex key milliseconds value
del
append
# 递增,key不存在则value置为0,value非数组类型则报错
incr k
# 递减
decr k
# 能指定步长的递增
incrby k n
# 能指定步长的递减
decrby k n
# n可以为浮点数
incrbyfloat k n
# offset开始用value覆盖,offset大于总长度则用0补齐
setrange key offset value
# 获取子串,下标可以为负数
getrange k m n
# 长度
strlen k
```

bit操作:字符串类型是以二进制形式存储,bit操作就是对这个二进制进行的操作
```shell
getbit key offset
setbit key offset
# 统计二进制存储中1的个数
bitcount key
# 对二进制进行与或非,异或运算,
bitop [and|or|not|xor] destkey key1 key2
```

nil:空

## list

基于双向循环链表实现, 栈

```shell
# 入栈
lpush
rpush
# 出栈
lpop
rpop
# 阻塞式弹出
blpop
brpop
ltrim key start end

# 出栈, 0 -1:全部取出
lrange key start stop
llen key
lindex key index
```

## hash

```shell
hset
hget

hmset
hmget
hgetall
hdel
hincrby
hlen

```

## set

无序, 不可重复

集合
```shell
# 增加元素
sadd key member [member ...]
# 删除元素
srem key member [member ...]
# 判断存在
sismember key member
# 元素个数
scard key
# 遍历
smembers key
# 随机返回count个value
srandmember key [count]
# 和srandmember相似,但会出栈
spop key [count]
# 跨集合移动元素
smove key1 key2 value
# 集合的差集
sdiff key1 key2
# 保存差集到destkey
sdiffstore destkey key1 key2
# 交集
sinter
sinterstore
# 并集
sunion
sunionstore
```

## zset

有序set

zadd
zrange
zrem
zscore
zrevrange

参数:
withscores



# 调用Redis

```java
// 方式1
Jedis jedis = new Jedis("127.0.0.1", 6379);
// 方式2
JedisPool pool = new JedisPool("127.0.0.1", 6379);
Jedis jedis = pool.getResource();


jedis.close();
pool.close();
```

```python

```

# 持久化

|方案|说明|持有化文件|优点|缺点|
|:---|:---|:---|:---|:---|
|RDB|间隔时间保存,用数据集快照的方式记录redis数据库的所有键值对, 默认方案|dump.rdb|1. 只有一个文件dump.rdb，方便持久化.</br>2. 容灾性好，一个文件可以保存到安全的磁盘.</br>3. 性能最大化，fork子进程来完成写操作，让主进程继续处理命令，所以是IO最大化.</br>4. 相对于数据集大时，比AOF的启动效率更高.|数据安全性低|
|AOF|实时保存,所有的命令行记录以redis命令请求协议的格式保存为aof文件|appendonly.aof|1. 数据安全，aof持久化可以配置appendfsync属性，有always，每进行一次命令操作就记录到aof文件中一次.<br/>2. 通过append模式写文件，即使中途服务器宕机，可以通过redis-check-aof工具解决数据一致性问题.<br/>3. AOF机制的rewrite模式.|1. 文件会比RDB形式的文件大.<br/>2. 数据集大的时候，比rdb启动效率低.|

```shell
# appendonly no
# 使用aof方案
appendonly yes
```


# 主从复制

1. 从-->主:sync
2. 主-->从:dump.rdb
3. 主-->从:发送缓冲获得写命令

> 从一般只读

从redis.conf:
```
slaveof 127.0.0.1 6379
```

访问从
redis-cli -p 6380


<!--
Redis有哪些数据结构?
字符串String,字典Hash,列表List,集合Set,有序集合SortedSet.

如果你是Redis中高级用户,还需要加上下面几种数据结构HyperLogLog,Geo,Pub/Sub.

如果你说还玩过Redis Module,像BloomFilter,RedisSearch,Redis-ML,面试官得眼睛就开始发亮了.

使用过Redis分布式锁么,它是什么回事?
先拿setnx来争抢锁,抢到之后,再用expire给锁加一个过期时间防止锁忘记了释放.

如果在setnx之后执行expire之前进程意外crash或者要重启维护了,那会怎么样?

这时候你要给予惊讶的反馈：唉,是喔,这个锁就永远得不到释放了.紧接着你需要抓一抓自己得脑袋,故作思考片刻,好像接下来的结果是你主动思考出来的,然后回答：我记得set指令有非常复杂的参数,这个应该是可以同时把setnx和expire合成一条指令来用的！对方这时会显露笑容,心里开始默念：摁,这小子还不错.



假如Redis里面有1亿个key,其中有10w个key是以某个固定的已知的前缀开头的,如果将它们全部找出来?
使用keys指令可以扫出指定模式的key列表.

对方接着追问：如果这个redis正在给线上的业务提供服务,那使用keys指令会有什么问题?

这个时候你要回答redis关键的一个特性：redis的单线程的.keys指令会导致线程阻塞一段时间,线上服务会停顿,直到指令执行完毕,服务才能恢复.这个时候可以使用scan指令,scan指令可以无阻塞的提取出指定模式的key列表,但是会有一定的重复概率,在客户端做一次去重就可以了,但是整体所花费的时间会比直接用keys指令长.



使用过Redis做异步队列么,你是怎么用的?
一般使用list结构作为队列,rpush生产消息,lpop消费消息.当lpop没有消息的时候,要适当sleep一会再重试.

如果对方追问可不可以不用sleep呢?list还有个指令叫blpop,在没有消息的时候,它会阻塞住直到消息到来.

如果对方追问能不能生产一次消费多次呢?使用pub/sub主题订阅者模式,可以实现1:N的消息队列.

如果对方追问pub/sub有什么缺点?在消费者下线的情况下,生产的消息会丢失,得使用专业的消息队列如rabbitmq等.

如果对方追问redis如何实现延时队列?我估计现在你很想把面试官一棒打死如果你手上有一根棒球棍的话,怎么问的这么详细.但是你很克制,然后神态自若的回答道：使用sortedset,拿时间戳作为score,消息内容作为key调用zadd来生产消息,消费者用zrangebyscore指令获取N秒之前的数据轮询进行处理.


如果有大量的key需要设置同一时间过期,一般需要注意什么?
如果大量的key过期时间设置的过于集中,到过期的那个时间点,redis可能会出现短暂的卡顿现象.一般需要在时间上加一个随机值,使得过期时间分散一些.

Redis如何做持久化的?
bgsave做镜像全量持久化,aof做增量持久化.因为bgsave会耗费较长时间,不够实时,在停机的时候会导致大量丢失数据,所以需要aof来配合使用.在redis实例重启时,会使用bgsave持久化文件重新构建内存,再使用aof重放近期的操作指令来实现完整恢复重启之前的状态.

对方追问那如果突然机器掉电会怎样?取决于aof日志sync属性的配置,如果不要求性能,在每条写指令时都sync一下磁盘,就不会丢失数据.但是在高性能的要求下每次都sync是不现实的,一般都使用定时sync,比如1s1次,这个时候最多就会丢失1s的数据.

对方追问bgsave的原理是什么?你给出两个词汇就可以了,fork和cow.fork是指redis通过创建子进程来进行bgsave操作,cow指的是copy on write,子进程创建后,父子进程共享数据段,父进程继续提供读写服务,写脏的页面数据会逐渐和子进程分离开来.

Pipeline有什么好处,为什么要用pipeline?
可以将多次IO往返的时间缩减为一次,前提是pipeline执行的指令之间没有因果相关性.使用redis-benchmark进行压测的时候可以发现影响redis的QPS峰值的一个重要因素是pipeline批次指令的数目.

Redis的同步机制了解么?
Redis可以使用主从同步,从从同步.
第一次同步时,主节点做一次bgsave,并同时将后续修改操作记录到内存buffer,待完成后将rdb文件全量同步到复制节点,复制节点接受完成后将rdb镜像加载到内存.加载完成后,再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程.

是否使用过Redis集群,集群的原理是什么?

Redis Sentinal着眼于高可用,在master宕机时会自动将slave提升为master,继续提供服务.

Redis Cluster着眼于扩展性,在单个redis内存不足时,使用Cluster进行分片存储.
-->

[![](https://static.segmentfault.com/v-5b1df2a7/global/img/creativecommons-cc.svg)](https://creativecommons.org/licenses/by-nc-nd/4.0/)